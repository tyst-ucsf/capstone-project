{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc3af308-512a-44a7-92de-2b177695cb73",
   "metadata": {},
   "source": [
    "This notebook is for combining all of the RESULTS.CSV files across all participant folders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17ee3a8-713c-4787-9bd2-332486c998bb",
   "metadata": {},
   "source": [
    "Plan: Cycle through all of the folders, obtain name and other rows, add this to a dataframe, then export this as a giant csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fbfdb7-d815-4083-ae9c-4136c398c147",
   "metadata": {},
   "source": [
    "Will also then go in and add if it was TB- or TB+ based on Excel sheet I already have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b0af3d9-9b34-48e1-9f19-6386c9853e9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T19:58:14.535696Z",
     "iopub.status.busy": "2025-04-07T19:58:14.534481Z",
     "iopub.status.idle": "2025-04-07T19:58:15.159304Z",
     "shell.execute_reply": "2025-04-07T19:58:15.159014Z",
     "shell.execute_reply.started": "2025-04-07T19:58:14.535630Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [PID, CAS, ID, RT, AreaPct]\n",
      "Index: []\n",
      "        PK       RT Area Pct                                      Library/ID  \\\n",
      "21035    1   3.1552   0.0444                             Heptane, 2,3-epoxy-   \n",
      "21036    2   3.1678   0.0407                                     Heptadecane   \n",
      "21037    3   3.2332   0.0085         Acetic acid, [(aminocarbonyl)amino]oxo-   \n",
      "21038    4   3.3008   0.0657                            1-Propene, 2-methyl-   \n",
      "21039    5   3.3468   0.0058                                         Butanal   \n",
      "...    ...      ...      ...                                             ...   \n",
      "53105  196  19.8556   0.0602  Naphthalene, 1,2,3-trimethyl-4-propenyl-, (E)-   \n",
      "53106  197  19.9303   0.0397  Naphthalene, 1,2,3-trimethyl-4-propenyl-, (E)-   \n",
      "53107  198  20.4434   0.0272                           Phenol, p-tert-butyl-   \n",
      "53108  199  20.5981   0.0439             Phenol, 3,5-bis(1,1-dimethylethyl)-   \n",
      "53109  200  20.8514   0.0362                        Carbazole, 3,6-dimethyl-   \n",
      "\n",
      "          Ref          CAS Qual                     PID  \n",
      "21035    8307  014925-96-3   46      HC-001_SC-B49239.D  \n",
      "21036  112530  000629-78-7   52      HC-001_SC-B49239.D  \n",
      "21037   15746  000585-05-7   47      HC-001_SC-B49239.D  \n",
      "21038     205  000115-11-7   43      HC-001_SC-B49239.D  \n",
      "21039     730  000123-72-8   40      HC-001_SC-B49239.D  \n",
      "...       ...          ...  ...                     ...  \n",
      "53105   74608  026137-53-1   91  R2D204_049_MK-486326.D  \n",
      "53106   74608  026137-53-1   76  R2D204_049_MK-486326.D  \n",
      "53107   24389  000098-54-4   95  R2D204_049_MK-486326.D  \n",
      "53108   70656  001138-52-9   86  R2D204_049_MK-486326.D  \n",
      "53109   60752  005599-50-8   64  R2D204_049_MK-486326.D  \n",
      "\n",
      "[63476 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "parent_folder = '/Users/tylerstepaniak/Library/Mobile Documents/com~apple~CloudDocs/IGHS/Capstone/Data/GC Files'\n",
    "\n",
    "# Walk through all subdirectories of the parent folder\n",
    "for root, dirs, files in os.walk(parent_folder):\n",
    "    if 'RESULTS.CSV' in files:\n",
    "        file_path = os.path.join(root, 'RESULTS.CSV')\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, skiprows=7, header=None)  # reads from column 8, down.\n",
    "            subset = df.iloc[:, 1:8].copy()  # grabs columns B to H\n",
    "            subset.columns = [\"PK\", \"RT\", \"Area Pct\", \"Library/ID\", \"Ref\", \"CAS\", \"Qual\"]\n",
    "            subset[\"PID\"] = os.path.basename(root)  # grabs PID\n",
    "            dfs.append(subset)\n",
    "        except Exception as e:\n",
    "            print(f'Error reading {file_path}: {e}')\n",
    "\n",
    "# adds everything to one DF\n",
    "if dfs:\n",
    "    final_df = pd.concat(dfs, ignore_index=True)\n",
    "    final_df = final_df.sort_values(by=[\"PID\", \"PK\"])\n",
    "    print(final_df)\n",
    "    final_df.to_csv('intial_output.csv', index=False)  # pushes to csv file\n",
    "else:\n",
    "    print(\"Something went wrong, go grab a coffee\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e14631-cc8c-4e05-aa6e-56a6e32c8ec1",
   "metadata": {},
   "source": [
    "Next step was a QC check comparing the output of:\n",
    "ls -d */ | sed 's:/$::' | pbcopy\n",
    "from terminal with the output excel file, which is now shown as 'verified_inital_output.csv' and completed in Excel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465379d0-0415-4ee7-abc7-82bfa8c9c838",
   "metadata": {},
   "source": [
    "QC check passed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07915a0-374d-4bf4-a591-c4d296878b10",
   "metadata": {},
   "source": [
    "Now, going to work on organizing the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3add2597-d00e-4404-99e2-f5a16f478133",
   "metadata": {},
   "source": [
    "TODO: Will need to rerun once more demographics are obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "abfa3d93-39c6-4d42-ab8b-82964cff3ae0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T21:24:05.234709Z",
     "iopub.status.busy": "2025-04-07T21:24:05.233592Z",
     "iopub.status.idle": "2025-04-07T21:24:05.538653Z",
     "shell.execute_reply": "2025-04-07T21:24:05.538310Z",
     "shell.execute_reply.started": "2025-04-07T21:24:05.234641Z"
    }
   },
   "outputs": [],
   "source": [
    "# generating blank df\n",
    "\n",
    "df_main1 = pd.DataFrame(\n",
    "    {'PID': [], 'CAS': [], 'Library/ID': [], 'RT': [], 'Area Pct': []}\n",
    "    )\n",
    "\n",
    "# print(df_main1)  # checking\n",
    "\n",
    "verified_initial_output_df = pd.read_csv('initial_output.csv')\n",
    "# print(verified_initial_output_df)  # checking that it is the correct csv\n",
    "\n",
    "df_main1 = pd.concat([df_main1, verified_initial_output_df], ignore_index=True)\n",
    "df_main1.rename(columns={'Library/ID': 'ID'})\n",
    "df_main1.drop(['Ref', 'Qual'], axis=1, inplace=True)\n",
    "# print(df_main1)\n",
    "\n",
    "# Renaming file names to standardize them and adding demographics\n",
    "df_demographics = pd.read_excel('/Users/tylerstepaniak/Library/Mobile Documents/com~apple~CloudDocs/IGHS/Capstone/Data/Master Data Spectra.xlsx')\n",
    "# print(df_demographics)\n",
    "df_main1 = pd.merge(df_main1, df_demographics, on='PID', how='left')\n",
    "# print(df_main1)\n",
    "df_main1.drop(['PID', 'Combined ID', 'PID-temp'], axis=1, inplace=True)\n",
    "# print(df_main1)\n",
    "df_main1.rename(columns={'Combined ID Clean': 'PID', 'Library/ID': 'ID'}, inplace=True)\n",
    "\n",
    "df_main1 = df_main1[['PID', 'File Name Standardized', 'Study', 'TB Status', 'HIV Status', 'Age', 'BMI', 'PK', 'CAS', 'ID', 'RT', 'Area Pct']]\n",
    "df_main1\n",
    "df_main1.to_csv('df_main1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc02b10-89fc-4651-b84e-55ba72402931",
   "metadata": {},
   "source": [
    "Data has now been placed into a master dataframe caled df_main1.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
